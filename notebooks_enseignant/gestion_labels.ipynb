{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "D'abord : se logguer à un compte gmail \\\n",
        "login : eleveenmi@gmail.com  (i=1,2,3,..) \\\n",
        "mwd : pwdeleveEnmi (i=1,2,3,..)"
      ],
      "metadata": {
        "id": "x4drUtTF40aM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I) Installations et imports"
      ],
      "metadata": {
        "id": "DvkSOtpFO5vm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SY7VMiH2Qvkq",
        "outputId": "8312cb4e-2f25-46fc-fdd6-6ce28b66e4de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.1)\n",
            "Requirement already satisfied: gspread_dataframe in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from gspread_dataframe) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread_dataframe) (1.17.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2025.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "# Google sheet\n",
        "!pip install --upgrade gspread gspread_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gspread\n",
        "from google.colab import drive\n",
        "from google.colab import output\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import shutil\n",
        "import tarfile\n",
        "from pathlib import Path\n",
        "import random\n",
        "from IPython.display import display, clear_output, Javascript, HTML\n",
        "import ipywidgets as widgets\n",
        "from base64 import b64encode\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "import re\n",
        "# Spécifique au TP :\n",
        "! git clone https://github.com/nanopiero/intro-ia-secondes-2025.git\n",
        "! cp intro-ia-secondes-2025/utils/annotation.py .\n",
        "! cp intro-ia-secondes-2025/utils/configuration.py .\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "from importlib import reload\n",
        "import configuration as cf\n",
        "import annotation as an\n",
        "# reload(cf)\n",
        "# reload(an)\n",
        "def count_files_in_subfolders(root_folder):\n",
        "    total = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(root_folder):\n",
        "        if dirpath != root_folder:  # only count files in subfolders\n",
        "            total += len(filenames)\n",
        "    return total\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def plot_first_image_in_subfolder(root_folder, subfolder='21'):\n",
        "    subfolder_path = os.path.join(root_folder, subfolder)\n",
        "    image_files = sorted([\n",
        "        f for f in os.listdir(subfolder_path)\n",
        "        if os.path.isfile(os.path.join(subfolder_path, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp'))\n",
        "    ])\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No images found in {subfolder_path}\")\n",
        "        return\n",
        "\n",
        "    image_path = os.path.join(subfolder_path, image_files[8])\n",
        "    img = mpimg.imread(image_path)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"First image in {subfolder_path}\")\n",
        "    plt.show()\n",
        "\n",
        "def show_annotation_dashboard(groups, group2sheeturl, gc):\n",
        "    rare_classes = {71, 72, 73, 41, 42, 43, 23, 44, 100}\n",
        "    group_counts = {}\n",
        "    group_rare_counts = {}\n",
        "\n",
        "    for group in groups:\n",
        "        url = group2sheeturl[group]\n",
        "        try:\n",
        "            sheet = gc.open_by_url(url).sheet1\n",
        "            df = get_as_dataframe(sheet, evaluate_formulas=True)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading sheet for group {group}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Skip if only headers or no valid Classe\n",
        "        if df.empty or not set(df.columns).issuperset({\"Image\", \"Classe\"}):\n",
        "            continue\n",
        "        df = df.dropna(subset=[\"Classe\"])\n",
        "        df[\"Classe\"] = pd.to_numeric(df[\"Classe\"], errors=\"coerce\")\n",
        "        df = df.dropna(subset=[\"Classe\"])\n",
        "        if df.empty:\n",
        "            continue\n",
        "\n",
        "        group_counts[group] = len(df)\n",
        "        group_rare_counts[group] = df[df[\"Classe\"].isin(rare_classes)][\"Classe\"].value_counts().to_dict()\n",
        "\n",
        "    valid_groups = list(group_counts.keys())\n",
        "    if not valid_groups:\n",
        "        display(HTML(\"<b style='color:red'>Aucune donnée annotée disponible.</b>\"))\n",
        "        return\n",
        "\n",
        "    # Build table content as list of lists (rows of cells)\n",
        "    table_rows = []\n",
        "\n",
        "    # Header\n",
        "    header_row = [\"groupe\"] + [str(g) for g in valid_groups] + [\"total\"]\n",
        "    table_rows.append(header_row)\n",
        "\n",
        "    # Label count row\n",
        "    counts = [group_counts[g] for g in valid_groups]\n",
        "    max_count = max(counts)\n",
        "    min_count = min(counts)\n",
        "    total_count = sum(counts)\n",
        "    count_row = [\"Labels\"]\n",
        "    for c in counts:\n",
        "        cell_style = \"background-color:#f88;\" if c == max_count else \"background-color:#88f;\" if c == min_count else \"\"\n",
        "        count_row.append((str(c), cell_style))\n",
        "    count_row.append((str(total_count), \"\"))\n",
        "\n",
        "    # Rare class count row\n",
        "    rare_total = 0\n",
        "    rare_row = [(\"Classes rares\", \"background-color:#fcc;\")]\n",
        "    for g in valid_groups:\n",
        "        rare_sum = sum(group_rare_counts[g].values())\n",
        "        rare_total += rare_sum\n",
        "        rare_row.append((str(rare_sum), \"background-color:#fcc;\"))\n",
        "    rare_row.append((str(rare_total), \"background-color:#fcc;\"))\n",
        "\n",
        "    # Function to render a row with optional style per cell\n",
        "    def render_row(cells, is_header=False):\n",
        "        html = \"<tr>\"\n",
        "        for cell in cells:\n",
        "            if isinstance(cell, tuple):\n",
        "                content, style = cell\n",
        "            else:\n",
        "                content, style = cell, \"\"\n",
        "            tag = \"th\" if is_header else \"td\"\n",
        "            html += f\"<{tag} style='min-width:80px; padding:10px; text-align:center; {style}'>{content}</{tag}>\"\n",
        "        html += \"</tr>\"\n",
        "        return html\n",
        "\n",
        "    # Assemble HTML table\n",
        "    html = \"<table style='border-collapse:collapse; font-family:monospace; font-size:16px;'>\"\n",
        "    html += render_row(table_rows[0], is_header=True)\n",
        "    html += render_row(count_row)\n",
        "    html += render_row(rare_row)\n",
        "    html += \"</table>\"\n",
        "\n",
        "    display(HTML(html))"
      ],
      "metadata": {
        "id": "GMfMBmwu4uec",
        "outputId": "4ad6eff7-b1aa-49de-8af2-5a0b7cc9ba10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'intro-ia-secondes-2025' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II) Authentification"
      ],
      "metadata": {
        "id": "ngJOgPdrPC8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cf.group2sheets"
      ],
      "metadata": {
        "id": "VXeXTTV1pGXo",
        "outputId": "be0e6126-d0fc-4711-ef75-c332cc592933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'https://docs.google.com/spreadsheets/d/1sjvrkLMEY0YXAyXU9Ad8i49J29jCmKkJb85T2pZ2CS8',\n",
              " 1: 'https://docs.google.com/spreadsheets/d/1sjvrkLMEY0YXAyXU9Ad8i49J29jCmKkJb85T2pZ2CS8',\n",
              " 2: 'https://docs.google.com/spreadsheets/d/1Npi7H-Y-P60QBODOL8Q5ArQHr5dIn9mOuYv67LLHcNE',\n",
              " 3: 'https://docs.google.com/spreadsheets/d/1I_ZwJrPt1AO_tQJSX2JBreFFhAlsF7kITH9p_1gDhks',\n",
              " 4: 'https://docs.google.com/spreadsheets/d/1e1LnjbLKoZ_JxYfGLu1nFIQWyioNt4AV_Y9C1CUqiWI',\n",
              " 5: 'https://docs.google.com/spreadsheets/d/1unaaeXdGVdC_1JMMVSBUgxc6vdrJzE16lTiP6OBEl04',\n",
              " 6: 'https://docs.google.com/spreadsheets/d/1odXOBEiNbFQ48NALzTEmCs7LDlBHWARdsivL8rO47fw',\n",
              " 7: 'https://docs.google.com/spreadsheets/d/1v7gJmdK1AqMelBRaksIcrIN_mDjobH8wxMxfLbiKlS8',\n",
              " 8: 'https://docs.google.com/spreadsheets/d/1chlVgydwqpQYq44ynEWX_I0QVtWsUaYfwqVSptTD-dA',\n",
              " 9: 'https://docs.google.com/spreadsheets/d/1x295asse_gh31-EzXQYFUSIkpbLe-hvYwWAxyr1c_ag',\n",
              " 10: 'https://docs.google.com/spreadsheets/d/1QKZuVjBd1SOmAZvg1zA4vnzLnh8DXVzDouwA941WB2I',\n",
              " 11: 'https://docs.google.com/spreadsheets/d/1oNurDfrYvCr0hnawUz432Dyh8Mkunk820GiDoa1Sz_E',\n",
              " 12: 'https://docs.google.com/spreadsheets/d/1EgmnmcX8jMXZmz6s_-oW473FnuT3HgPjlSnqCcJTrP4',\n",
              " 13: 'https://docs.google.com/spreadsheets/d/1KT4RXpX3FkR2APlGXhD54euEpPWHbFZKrxoWdFzeqog'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pour colab :\n",
        "auth.authenticate_user()\n",
        "# pour accéder aux fichiers google (google sheet)\n",
        "creds, _ = default()  # or use service account\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# montage du drive :\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Z6QHIJjpQwYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859e5089-6529-4575-db53-75df98a502de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III) Dashboard"
      ],
      "metadata": {
        "id": "YfKdwUNe_Zbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groupes = list(np.arange(0,14))\n",
        "\n",
        "# Assuming `gc = gspread.authorize(creds)` already done\n",
        "show_annotation_dashboard(groupes, cf.group2sheets, gc)"
      ],
      "metadata": {
        "id": "IULNAwT0yIqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV) Récupération des images annotées"
      ],
      "metadata": {
        "id": "GgVAnYGo-bik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import tarfile\n",
        "from collections import defaultdict\n",
        "\n",
        "import gspread\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from gspread_dataframe import get_as_dataframe\n",
        "\n",
        "# Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Configuration (import or define locally)\n",
        "group2sheet_url = cf.group2sheets\n",
        "\n",
        "group2direction_and_starthour = cf.group2direction_and_starthour\n",
        "\n",
        "classes_to_sample = [1, 20, 21, 30, 40, 50, 60, 61, 70, 74, 75, 82]  # Extend this list as needed\n",
        "base_drive_path = '/content/drive/MyDrive/stage_secondes_2025'\n",
        "\n",
        "# Create target directories\n",
        "os.makedirs('classification', exist_ok=True)\n",
        "for cls in classes_to_sample:\n",
        "    os.makedirs(f'classification/{cls}', exist_ok=True)\n",
        "\n",
        "# Authorize gspread (you must have already set up your credentials)\n",
        "# gc = gspread.authorize(creds)  # Make sure creds is defined properly\n",
        "\n",
        "for group, sheet_url in group2sheet_url.items():\n",
        "    print(group)\n",
        "    direction, starthour = group2direction_and_starthour[group]\n",
        "    tar_name = f\"{group}_{direction}_{starthour}.tar.gz\"\n",
        "    tar_path = os.path.join(base_drive_path, tar_name)\n",
        "\n",
        "    print(f\"\\nProcessing group {group}: extracting {tar_name}...\")\n",
        "\n",
        "    try:\n",
        "        # Load and filter sheet\n",
        "        sheet = gc.open_by_url(sheet_url).sheet1\n",
        "        df = get_as_dataframe(sheet).dropna(subset=[\"Classe\", \"Image\"])\n",
        "        df = df[df['Classe'].astype(int).isin(classes_to_sample)]\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load sheet for group {group}: {e}\")\n",
        "        continue\n",
        "\n",
        "    if df.empty:\n",
        "        print(f\"No valid entries for group {group}.\")\n",
        "        continue\n",
        "\n",
        "    # Extract tar\n",
        "    try:\n",
        "        with tarfile.open(tar_path, \"r:gz\") as tar:\n",
        "            tar.extractall()\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting {tar_path}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Move images to classification folders\n",
        "    for _, row in df.iterrows():\n",
        "        image_name = row['Image']\n",
        "        cls = int(row['Classe'])\n",
        "        timestamp = image_name.split('_')[1].replace('.jpg', '')\n",
        "        image_path = os.path.join(f\"{group}_{direction}_{starthour}\", timestamp, image_name)\n",
        "\n",
        "        if os.path.exists(image_path):\n",
        "            shutil.copy(image_path, f\"classification/{cls}/\")\n",
        "        else:\n",
        "            print(f\"Missing image {image_path}\")\n",
        "\n",
        "    # Clean up\n",
        "    shutil.rmtree(f\"{group}_{direction}_{starthour}\", ignore_errors=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "-LT_wM3y5D4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = 'classification'\n",
        "print(f\"Total files in subfolders: {count_files_in_subfolders(folder_path)}\")"
      ],
      "metadata": {
        "id": "wV_voxph7EP1",
        "outputId": "f9ec2d84-d1f8-4f35-b6ea-3ba21f42c97b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files in subfolders: 422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_folder = '/content/classification'\n",
        "plot_first_image_in_subfolder(root_folder)\n"
      ],
      "metadata": {
        "id": "K5u7E8FW7rVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV) Split train val test :"
      ],
      "metadata": {
        "id": "Sw-CN1lqPL7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "from math import ceil\n",
        "\n",
        "# Create base folders\n",
        "os.makedirs('learning/train', exist_ok=True)\n",
        "os.makedirs('learning/val', exist_ok=True)\n",
        "os.makedirs('test', exist_ok=True)\n",
        "\n",
        "classification_dir = 'classification'\n",
        "learning_dir = 'learning'\n",
        "test_dir = 'test'\n",
        "\n",
        "for class_name in os.listdir(classification_dir):\n",
        "    class_path = os.path.join(classification_dir, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    # Create output class folders\n",
        "    os.makedirs(os.path.join(learning_dir, 'train', class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(learning_dir, 'val', class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
        "\n",
        "    # Gather all images and their date-based split keys\n",
        "    image_files = [f for f in os.listdir(class_path) if f.endswith('.jpg')]\n",
        "    images_by_modulo = {0: [], 1: [], 2: []}\n",
        "\n",
        "    for img in image_files:\n",
        "        try:\n",
        "            tsd = int(img.split('_')[1][:8])\n",
        "            mod = tsd % 3\n",
        "            images_by_modulo[mod].append(img)\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping malformed image name: {img}\")\n",
        "            continue\n",
        "\n",
        "    total = len(image_files)\n",
        "    n_test = ceil(total * 0.2)\n",
        "    n_val = ceil(total * 0.2)\n",
        "    count_test = count_val = 0\n",
        "\n",
        "    for mod in [0, 1, 2]:\n",
        "        for img in images_by_modulo[mod]:\n",
        "            src = os.path.join(class_path, img)\n",
        "\n",
        "            if count_test < n_test:\n",
        "                dst = os.path.join(test_dir, class_name, img)\n",
        "                shutil.copy(src, dst)\n",
        "                count_test += 1\n",
        "            elif count_val < n_val:\n",
        "                dst = os.path.join(learning_dir, 'val', class_name, img)\n",
        "                shutil.copy(src, dst)\n",
        "                count_val += 1\n",
        "            else:\n",
        "                dst = os.path.join(learning_dir, 'train', class_name, img)\n",
        "                shutil.copy(src, dst)\n"
      ],
      "metadata": {
        "id": "RIaQEjuwA9Zr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "base_dirs = {\n",
        "    \"train\": \"learning/train\",\n",
        "    \"val\": \"learning/val\",\n",
        "    \"test\": \"test\"\n",
        "}\n",
        "\n",
        "counts = defaultdict(dict)\n",
        "for split, path in base_dirs.items():\n",
        "    for class_name in os.listdir(path):\n",
        "        class_path = os.path.join(path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            n_images = len([f for f in os.listdir(class_path) if f.endswith('.jpg')])\n",
        "            counts[class_name][split] = n_images\n",
        "\n",
        "df = pd.DataFrame(counts).T.fillna(0).astype(int)\n",
        "df.loc['TOTAL'] = df.sum()\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "kCY9KbWJBsRp",
        "outputId": "582331ad-d59c-488e-9fec-559b0fad7f8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       train  val  test\n",
            "1         66   23    23\n",
            "50        12    4     4\n",
            "60         2    1     1\n",
            "30        21    8     8\n",
            "82         2    2     2\n",
            "70         0    0     1\n",
            "40        24    8     8\n",
            "74         6    2     2\n",
            "75        42   15    15\n",
            "21        26   10    10\n",
            "20        21    8     8\n",
            "61        21    8     8\n",
            "TOTAL    243   89    90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#V) tar it and automatic share"
      ],
      "metadata": {
        "id": "eQ6hjTLlQMR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "from google.colab import drive\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# Mount Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Tar the folders\n",
        "def make_tar(folder_name):\n",
        "    with tarfile.open(f\"{folder_name}.tar.gz\", \"w:gz\") as tar:\n",
        "        tar.add(folder_name, arcname=os.path.basename(folder_name))\n",
        "\n",
        "make_tar(\"learning\")\n",
        "make_tar(\"test\")\n",
        "\n",
        "# Move to your target Drive folder\n",
        "drive_folder = \"/content/drive/MyDrive/stage_secondes_2025\"\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "shutil.move(\"learning.tar.gz\", os.path.join(drive_folder, \"learning.tar.gz\"))\n",
        "shutil.move(\"test.tar.gz\", os.path.join(drive_folder, \"test.tar.gz\"))\n"
      ],
      "metadata": {
        "id": "Ysarx7mWRyha",
        "outputId": "1cbabf82-6283-4aec-c524-d0b4636db17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/stage_secondes_2025/test.tar.gz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls /content/drive/MyDrive/stage_secondes_2025"
      ],
      "metadata": {
        "id": "dJ1xHah2C_xw",
        "outputId": "aa98e8bb-458c-4053-9adc-6d5d3e0b3b7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0_S_08H00.tar.gz   13_S_09H00.tar.gz  4_S_09H00.tar.gz  8_E_09H00.tar.gz\n",
            "10_S_09H10.tar.gz  1_S_10H00.tar.gz   5_S_09H20.tar.gz  9_O_09H00.tar.gz\n",
            "11_S_09H04.tar.gz  2_S_08H20.tar.gz   6_S_09H40.tar.gz  learning.tar.gz\n",
            "12_S_09H02.tar.gz  3_S_08H40.tar.gz   7_N_09H00.tar.gz  test.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Drive API auth (uses your Colab credentials)\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "import mimetypes\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Get the file ID for learning.tar.gz\n",
        "def get_file_id_by_name(file_name, parent_folder_name=\"stage_secondes_2025\"):\n",
        "    query = f\"name = '{file_name}' and trashed = false\"\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id, name, parents)\").execute()\n",
        "    files = results.get(\"files\", [])\n",
        "    for file in files:\n",
        "        if parent_folder_name in file.get(\"parents\", []):\n",
        "            return file[\"id\"]\n",
        "    return files[0][\"id\"] if files else None\n",
        "\n",
        "file_id = get_file_id_by_name(\"learning.tar.gz\")\n",
        "\n",
        "# Share with eleveenm1..13@gmail.com\n",
        "for i in range(1, 2):\n",
        "    user_email = f\"eleveenm{i}@gmail.com\"\n",
        "    drive_service.permissions().create(\n",
        "        fileId=file_id,\n",
        "        body={\n",
        "            \"type\": \"user\",\n",
        "            \"role\": \"reader\",\n",
        "            \"emailAddress\": user_email\n",
        "        },\n",
        "        fields=\"id\"\n",
        "    ).execute()\n",
        "    print(f\"Shared with {user_email}\")\n"
      ],
      "metadata": {
        "id": "9B-54-XmDKMU",
        "outputId": "65ef3bec-4e34-47d8-ed5f-7ba1da29856a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shared with eleveenm1@gmail.com\n"
          ]
        }
      ]
    }
  ]
}