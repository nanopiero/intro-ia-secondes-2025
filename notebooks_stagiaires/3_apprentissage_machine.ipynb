{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "D'abord : se logguer à un compte gmail \\\n",
        "login : eleveenmi@gmail.com  (i=1,2,3,..) \\\n",
        "mwd : pwdeleveEnmi (i=1,2,3,..)\n",
        "\n",
        "Avant de lancer le notebook, il faut avoir déplace le fichier learning.tar.gz du dossier partagé dans le dossier `stage_secondes_2025`."
      ],
      "metadata": {
        "id": "x4drUtTF40aM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0) Installations, imports et fonctions"
      ],
      "metadata": {
        "id": "hUpDGBGNcU8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EElWQwAuWmZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Commencez par installer et faire les imports pour\n",
        " # avoir toutes les fonctions utiles\n",
        "!pip install -q plotly\n",
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from PIL import Image, ImageOps\n",
        "import random\n",
        "import torchvision.transforms as T\n",
        "from matplotlib import pyplot as plt\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Spécifique au TP :\n",
        "! git clone https://github.com/nanopiero/intro-ia-secondes-2025.git\n",
        "! cp intro-ia-secondes-2025/utils/apprentissage.py .\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "from importlib import reload\n",
        "import apprentissage\n",
        "# reload(apprentissage)\n",
        "\n",
        "from apprentissage import (\n",
        "    show_confusion_matrix_plotly,\n",
        "    get_valid_classes,\n",
        "    clean_directory,\n",
        "    apply_transforms,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomVerticalFlip,\n",
        "    RandomDistortion,\n",
        "    RandomCropping,\n",
        "    Rotation,\n",
        "    RandomColorJitter,\n",
        "    show_filters,\n",
        "    show_class_prediction_gallery_by_name,\n",
        "    find_file_id\n",
        ")\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E84jqJaAyuzp",
        "outputId": "51b0645d-3941-4448-bbf3-740b83606a28"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'intro-ia-secondes-2025'...\n",
            "remote: Enumerating objects: 243, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 243 (delta 69), reused 8 (delta 8), pack-reused 135 (from 1)\u001b[K\n",
            "Receiving objects: 100% (243/243), 7.99 MiB | 17.94 MiB/s, done.\n",
            "Resolving deltas: 100% (137/137), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I) Chargeons le jeu d'entraînement"
      ],
      "metadata": {
        "id": "DvkSOtpFO5vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# D'abord, chargeons les images\n",
        "tar_path = '/content/drive/MyDrive/stage_secondes_2025/learning.tar.gz'\n",
        "extract_path = '/content/'\n",
        "\n",
        "with tarfile.open(tar_path, 'r:gz') as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "\n",
        "# Ensuite précisons où sont les deux dossiers pour l'entraînelment et la validation\n",
        "base_dir = os.path.join(extract_path, 'learning')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')"
      ],
      "metadata": {
        "id": "8qADd3MIJALH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Si dossiers vides :\n",
        "valid_classes = get_valid_classes(train_dir, val_dir)\n",
        "clean_directory(train_dir, valid_classes)\n",
        "clean_directory(val_dir, valid_classes)\n",
        "\n",
        "print(\"Nettoyage terminé. Nombre de classes restantes :\", sorted(valid_classes))"
      ],
      "metadata": {
        "id": "_fMHGrZtH5qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#II) Choix d'une augmentation de données"
      ],
      "metadata": {
        "id": "o42LKdtgE3NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargeons une image pour voir\n",
        "image_path = \"learning/train/21/\" + os.listdir(\"learning/train/21\")[0]\n",
        "img = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# Definissons notre série de transformations\n",
        "transforms = [\n",
        "    RandomVerticalFlip(),\n",
        "    RandomCropping(0.1),\n",
        "    Rotation(10),\n",
        "    RandomColorJitter(contrast=0.3, hue=0.05, saturation=0.3, brightness=0.3)\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Voyons l'image originale et sa transformée :\n",
        "aug_img = apply_transforms(img.copy(), transforms)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Augmented\")\n",
        "plt.imshow(aug_img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FjlMGiLQE1fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#III) Entraînement d'un réseau de neurones"
      ],
      "metadata": {
        "id": "yr2Vzu1xEPpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##III)1) Qu'est-ce qu'il y a dans un réseau de neurone (pour le traitement d'image) ?"
      ],
      "metadata": {
        "id": "YSGuMb6XPEqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Chargeons un ResNet50 dont les poids sont choisis au hasard, et un Resnet pré-entraîné sur ImageNet\n",
        "resnet_pretrained = models.resnet50(pretrained=True)\n",
        "resnet_random = models.resnet50(pretrained=False)\n",
        "\n",
        "# Get first conv layer weights: shape = [64, 3, 7, 7]\n",
        "w_pre = resnet_pretrained.conv1.weight.data.clone()\n",
        "w_rand = resnet_random.conv1.weight.data.clone()\n",
        "\n",
        "show_filters(w_rand, \"Random Init - First Conv Layer (R channel)\")\n",
        "show_filters(w_pre, \"Pretrained on ImageNet - First Conv Layer (R channel)\")\n",
        "del resnet_pretrained, resnet_random"
      ],
      "metadata": {
        "id": "MjPzObSZOcVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/vdumoulin/conv_arithmetic"
      ],
      "metadata": {
        "id": "WpM2Q0SMO7OT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.image-net.org/challenges/LSVRC/2012/index#task"
      ],
      "metadata": {
        "id": "Csh9R6puPO6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III)2) Comment entraîner un tel réseau ?"
      ],
      "metadata": {
        "id": "93MEaLkdPLHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CONFIGURATION  ====\n",
        "config = {\n",
        "    'architecture': 'resnet18',   # 'resnet18' or 'resnet50'\n",
        "    'freeze_backbone': False,\n",
        "    'learning_rate': 0.001,\n",
        "    'batch_size': 32,\n",
        "    'num_epochs': 5,\n",
        "    'image_size': 224,\n",
        "    'train_dir': 'learning/train',\n",
        "    'val_dir': 'learning/val',\n",
        "\n",
        "    'transforms': [\n",
        "        RandomVerticalFlip(),\n",
        "        RandomCropping(0.1),\n",
        "        Rotation(10),\n",
        "        RandomColorJitter(contrast=0.3, hue=0.05, saturation=0.3, brightness=0.3)\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "FQSrUXSuQ6k1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construisons des \"piocheurs\" et des \"chargeurs\"\n",
        "train_transform = T.Compose(config['transforms'] + [\n",
        "    T.Resize((config['image_size'], config['image_size'])),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "val_transform = T.Compose([\n",
        "    T.Resize((config['image_size'], config['image_size'])),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "train_set = ImageFolder(config['train_dir'], transform=train_transform)\n",
        "val_set = ImageFolder(config['val_dir'], transform=val_transform)\n",
        "class_names = train_set.classes\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Xnt7TRa5VlTA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lançons l'apprentissage :\n",
        "\n",
        "# Load model architecture\n",
        "if config['architecture'] == 'resnet18':\n",
        "    model = models.resnet18(pretrained=True)\n",
        "elif config['architecture'] == 'resnet50':\n",
        "    model = models.resnet50(pretrained=True)\n",
        "else:\n",
        "    raise ValueError(\"Unsupported architecture.\")\n",
        "\n",
        "# Freeze backbone if needed\n",
        "if config['freeze_backbone']:\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Replace classifier\n",
        "num_classes = len(class_names)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "\n",
        "# Metric tracking\n",
        "train_accs, val_accs = [], []\n",
        "train_bal_accs, val_bal_accs = [], []\n",
        "\n",
        "# === Training Loop ===\n",
        "for epoch in range(config['num_epochs']):\n",
        "    model.train()\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "    train_bal = balanced_accuracy_score(train_labels, train_preds)\n",
        "    train_accs.append(train_acc)\n",
        "    train_bal_accs.append(train_bal)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_preds, val_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_acc = accuracy_score(val_labels, val_preds)\n",
        "    val_bal = balanced_accuracy_score(val_labels, val_preds)\n",
        "    val_accs.append(val_acc)\n",
        "    val_bal_accs.append(val_bal)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{config['num_epochs']}: \"\n",
        "          f\"Train Acc: {train_acc:.3f}, Val Acc: {val_acc:.3f} | \"\n",
        "          f\"Train BalAcc: {train_bal:.3f}, Val BalAcc: {val_bal:.3f}\")\n"
      ],
      "metadata": {
        "id": "hyfgu7YhRNc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Voyons comment les scores ont progressé !\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(train_accs, label='Train Accuracy')\n",
        "plt.plot(val_accs, label='Val Accuracy')\n",
        "plt.plot(train_bal_accs, label='Train Balanced Acc', linestyle='--')\n",
        "plt.plot(val_bal_accs, label='Val Balanced Acc', linestyle='--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training & Validation Metrics')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oh2omuD0WR9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IV) Visualisation des prédictions sur le jeu de validation"
      ],
      "metadata": {
        "id": "xD0r6kGdEeBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Voyons la table de confusion sur le jeu de validation :\n",
        "show_confusion_matrix_plotly(model, val_loader, class_names, device)\n"
      ],
      "metadata": {
        "id": "nBM3ocRiV_Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Et quelques cas pris au hasard de bonnes/mauvaises prédictions :\n",
        "show_class_prediction_gallery_by_name(model, val_loader, class_names, device, class_name='20')"
      ],
      "metadata": {
        "id": "eIK95P3pYxvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#V) Sauvegarde du réseau et partage vers le compte central"
      ],
      "metadata": {
        "id": "1sEcB2MuEjY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Envoyez votre \"meilleure\" architecture pour comparaisons sur le jeu de test\n",
        "groupe = 14"
      ],
      "metadata": {
        "id": "4MW6PuEwaAxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model weights\n",
        "arch = config['architecture']\n",
        "imgsize = config['image_size']\n",
        "filename = f\"{groupe}_{arch}_{imgsize}.pth\"\n",
        "torch.save(model.state_dict(), filename)\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount drive if not already mounted\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_dir = \"/content/drive/MyDrive/stage_secondes_2025\"\n",
        "os.makedirs(drive_dir, exist_ok=True)\n",
        "\n",
        "# Move file\n",
        "dst_path = os.path.join(drive_dir, filename)\n",
        "shutil.move(filename, dst_path)\n",
        "print(f\"Saved to {dst_path}\")\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Find file ID by name in destination folder\n",
        "file_id = find_file_id(filename, drive_service)\n",
        "\n",
        "# Share with email\n",
        "drive_service.permissions().create(\n",
        "    fileId=file_id,\n",
        "    body={\n",
        "        'type': 'user',\n",
        "        'role': 'reader',\n",
        "        'emailAddress': 'tpdeeplearning@gmail.com'\n",
        "    },\n",
        "    fields='id'\n",
        ").execute()\n",
        "\n",
        "print(f\"Shared {filename} with tpdeeplearning@gmail.com\")"
      ],
      "metadata": {
        "id": "w9rleL9VXS_p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}