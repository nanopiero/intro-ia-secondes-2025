{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "D'abord : se logguer à un compte gmail \\\n",
        "login : eleveenmi@gmail.com  (i=1,2,3,..) \\\n",
        "mwd : pwdeleveEnmi (i=1,2,3,..)\n",
        "\n",
        "Avant de lancer le notebook, il faut avoir déplace le fichier learning.tar.gz du dossier partagé dans le dossier `stage_secondes_2025`."
      ],
      "metadata": {
        "id": "x4drUtTF40aM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0) Installations, imports et fonctions"
      ],
      "metadata": {
        "id": "hUpDGBGNcU8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EElWQwAuWmZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Commencez par installer et faire les imports pour\n",
        " # avoir toutes les fonctions utiles\n",
        "!pip install -q plotly\n",
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from PIL import Image, ImageOps\n",
        "import random\n",
        "import torchvision.transforms as T\n",
        "from matplotlib import pyplot as plt\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Spécifique au TP :\n",
        "! git clone https://github.com/nanopiero/intro-ia-secondes-2025.git\n",
        "! cp intro-ia-secondes-2025/utils/apprentissage.py .\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "from importlib import reload\n",
        "import apprentissage\n",
        "# reload(apprentissage)\n",
        "\n",
        "from apprentissage import (\n",
        "    show_confusion_matrix_plotly,\n",
        "    get_valid_classes,\n",
        "    clean_directory,\n",
        "    apply_transforms,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomVerticalFlip,\n",
        "    RandomDistortion,\n",
        "    RandomCropping,\n",
        "    Rotation,\n",
        "    RandomColorJitter,\n",
        "    show_filters,\n",
        "    show_class_prediction_gallery_by_name,\n",
        "    find_file_id\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E84jqJaAyuzp",
        "outputId": "d61d6a78-7745-4e1e-9c4c-0f143fce19fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'intro-ia-secondes-2025'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 239 (delta 67), reused 8 (delta 8), pack-reused 135 (from 1)\u001b[K\n",
            "Receiving objects: 100% (239/239), 7.98 MiB | 26.11 MiB/s, done.\n",
            "Resolving deltas: 100% (135/135), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "s3aCU26xzbLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Commencez par installer et faire les imports pour\n",
        " # avoir toutes les fonctions utiles\n",
        "!pip install -q plotly\n",
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from PIL import Image, ImageOps\n",
        "import random\n",
        "import torchvision.transforms as T\n",
        "from matplotlib import pyplot as plt\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Spécifique au TP :\n",
        "! git clone https://github.com/nanopiero/intro-ia-secondes-2025.git\n",
        "! cp intro-ia-secondes-2025/utils/annotation.py .\n",
        "! cp intro-ia-secondes-2025/utils/configuration.py .\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "from importlib import reload\n",
        "import configuration as cf\n",
        "import annotation as an\n",
        "# reload(cf)\n",
        "# reload(an)\n",
        "\n",
        "def show_confusion_matrix_plotly(model, val_loader, class_names):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x = x.to(device)\n",
        "            outputs = model(x)\n",
        "            preds.extend(outputs.argmax(1).cpu().numpy())\n",
        "            labels.extend(y.numpy())\n",
        "\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "\n",
        "    fig = px.imshow(\n",
        "        df_cm,\n",
        "        text_auto=True,\n",
        "        color_continuous_scale='Blues',\n",
        "        labels=dict(x=\"Predicted\", y=\"True\", color=\"Count\"),\n",
        "        title=\"Confusion Matrix (Validation Set)\",\n",
        "        width=800,\n",
        "        height=800\n",
        "    )\n",
        "    fig.update_layout(font=dict(size=14))\n",
        "    fig.show()\n",
        "\n",
        "def get_valid_classes(train_dir, val_dir, min_count=5):\n",
        "    train_classes = set(os.listdir(train_dir))\n",
        "    val_classes = set(os.listdir(val_dir))\n",
        "    common_classes = train_classes & val_classes\n",
        "    valid_classes = []\n",
        "\n",
        "    for cls in common_classes:\n",
        "        train_cls_path = os.path.join(train_dir, cls)\n",
        "        val_cls_path = os.path.join(val_dir, cls)\n",
        "\n",
        "        if not os.path.isdir(train_cls_path) or not os.path.isdir(val_cls_path):\n",
        "            continue\n",
        "\n",
        "        train_count = len([f for f in os.listdir(train_cls_path) if os.path.isfile(os.path.join(train_cls_path, f))])\n",
        "        val_count = len([f for f in os.listdir(val_cls_path) if os.path.isfile(os.path.join(val_cls_path, f))])\n",
        "\n",
        "        if train_count >= min_count and val_count >= min_count:\n",
        "            valid_classes.append(cls)\n",
        "\n",
        "    return set(valid_classes)\n",
        "def clean_directory(dir_path, valid_classes):\n",
        "    for cls in os.listdir(dir_path):\n",
        "        full_path = os.path.join(dir_path, cls)\n",
        "        if os.path.isdir(full_path) and cls not in valid_classes:\n",
        "            shutil.rmtree(full_path)\n",
        "\n",
        "\n",
        "# Apply each transform in the list sequentially\n",
        "def apply_transforms(img, transform_list):\n",
        "    for t in transform_list:\n",
        "        img = t(img)\n",
        "    return img\n",
        "\n",
        "class RandomHorizontalFlip:\n",
        "    def __call__(self, img):\n",
        "        if random.random() > 0.5:\n",
        "            return ImageOps.mirror(img)  # left ↔ right\n",
        "        return img\n",
        "\n",
        "class RandomVerticalFlip:\n",
        "    def __call__(self, img):\n",
        "        if random.random() > 0.5:\n",
        "            return ImageOps.flip(img)  # top ↕ bottom\n",
        "        return img\n",
        "\n",
        "class RandomDistortion:\n",
        "    def __init__(self, intensity=5):\n",
        "        self.intensity = intensity\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        dx = self.intensity\n",
        "        dy = self.intensity\n",
        "        coeffs = (\n",
        "            1, random.uniform(-dx/h, dx/h), 0,\n",
        "            random.uniform(-dy/w, dy/w), 1, 0\n",
        "        )\n",
        "        return img.transform(img.size, Image.AFFINE, coeffs)\n",
        "\n",
        "class RandomCropping:\n",
        "    def __init__(self, zoommax=0.1):\n",
        "        self.zoommax = zoommax\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        dw = int(random.uniform(0, self.zoommax) * w)\n",
        "        dh = int(random.uniform(0, self.zoommax) * h)\n",
        "        left = dw\n",
        "        top = dh\n",
        "        right = w - dw\n",
        "        bottom = h - dh\n",
        "        return img.crop((left, top, right, bottom)).resize((w, h))\n",
        "\n",
        "class Rotation:\n",
        "    def __init__(self, degreemax=10):\n",
        "        self.degreemax = degreemax\n",
        "\n",
        "    def __call__(self, img):\n",
        "        angle = random.uniform(-self.degreemax, self.degreemax)\n",
        "        return img.rotate(angle)\n",
        "\n",
        "class RandomColorJitter:\n",
        "    def __init__(self, contrast=0.2, hue=0.1, saturation=0.2, brightness=0.2):\n",
        "        self.transform = T.ColorJitter(\n",
        "            contrast=contrast,\n",
        "            hue=hue,\n",
        "            saturation=saturation,\n",
        "            brightness=brightness\n",
        "        )\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.transform(img)\n",
        "\n",
        "\n",
        "def show_filters(weights, title):\n",
        "    fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        filt = weights[i, 0, :, :].cpu().numpy()  # R channel\n",
        "        ax.imshow(filt, cmap='bwr', vmin=-0.2, vmax=0.2)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.92)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_class_prediction_gallery_by_name(model, val_loader, class_names, class_name, max_per_col=10):\n",
        "    assert class_name in class_names, f\"'{class_name}' not found in class names: {class_names}\"\n",
        "    K = class_names.index(class_name)\n",
        "\n",
        "    model.eval()\n",
        "    all_images, all_labels, all_preds = [], [], []\n",
        "\n",
        "    # Gather predictions and labels\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x = x.to(device)\n",
        "            preds = model(x).argmax(1).cpu()\n",
        "            all_images.extend(x.cpu())\n",
        "            all_labels.extend(y.cpu())\n",
        "            all_preds.extend(preds.cpu())\n",
        "\n",
        "    # Categorize samples\n",
        "    correct, missed, false_alarm = [], [], []\n",
        "    for img, label, pred in zip(all_images, all_labels, all_preds):\n",
        "        if label == K and pred == K:\n",
        "            correct.append((img, label, pred))\n",
        "        elif label == K and pred != K:\n",
        "            missed.append((img, label, pred))\n",
        "        elif label != K and pred == K:\n",
        "            false_alarm.append((img, label, pred))\n",
        "\n",
        "    def sample(lst): return random.sample(lst, min(len(lst), max_per_col))\n",
        "    correct_sample = sample(correct)\n",
        "    missed_sample = sample(missed)\n",
        "    false_alarm_sample = sample(false_alarm)\n",
        "\n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(max_per_col, 3, figsize=(12, 2.5 * max_per_col))\n",
        "    fig.suptitle(f'Class \"{class_name}\" (index {K}) — Prediction Gallery', fontsize=16)\n",
        "\n",
        "    for i in range(max_per_col):\n",
        "        for j, sample_list in enumerate([correct_sample, missed_sample, false_alarm_sample]):\n",
        "            ax = axes[i, j] if max_per_col > 1 else axes[j]\n",
        "            if i < len(sample_list):\n",
        "                img, label, pred = sample_list[i]\n",
        "                ax.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
        "                ax.set_title(f\"True: {class_names[label]}\\nPred: {class_names[pred]}\")\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "    col_titles = [\"Correct (TP)\", \"Missed (FN)\", \"False Alarm (FP)\"]\n",
        "    for j in range(3):\n",
        "        axes[0, j].set_title(col_titles[j], fontsize=14)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "def find_file_id(filename):\n",
        "    query = f\"name='{filename}' and trashed=false\"\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "    files = results.get(\"files\", [])\n",
        "    if not files:\n",
        "        raise FileNotFoundError(f\"{filename} not found in Drive.\")\n",
        "    return files[0]['id']\n",
        "\n"
      ],
      "metadata": {
        "id": "qETZFe0iIE6f",
        "outputId": "f05000fd-4de0-41c4-8249-65a990d80519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I) Chargeons le jeu d'entraînement"
      ],
      "metadata": {
        "id": "DvkSOtpFO5vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# D'abord, chargeons les images\n",
        "tar_path = '/content/drive/MyDrive/stage_secondes_2025/learning.tar.gz'\n",
        "extract_path = '/content/'\n",
        "\n",
        "with tarfile.open(tar_path, 'r:gz') as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "\n",
        "# Ensuite précisons où sont les deux dossiers pour l'entraînelment et la validation\n",
        "base_dir = os.path.join(extract_path, 'learning')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')"
      ],
      "metadata": {
        "id": "8qADd3MIJALH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "6b85c0eb-9708-447c-a202-d4f53293ea26"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/stage_secondes_2025/learning.tar.gz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-2804785582.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mextract_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r:gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1869\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown compression type %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1871\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"|\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/stage_secondes_2025/learning.tar.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Si dossiers vides :\n",
        "# Step 3: Check for common classes and filter those with >=10 elements in both\n",
        "valid_classes = get_valid_classes(train_dir, val_dir)\n",
        "\n",
        "# Step 4: Remove invalid class-subfolders\n",
        "clean_directory(train_dir, valid_classes)\n",
        "clean_directory(val_dir, valid_classes)\n",
        "\n",
        "print(\"Finished cleaning. Valid classes kept:\", sorted(valid_classes))"
      ],
      "metadata": {
        "id": "_fMHGrZtH5qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#II) Choix d'une augmentation de données"
      ],
      "metadata": {
        "id": "o42LKdtgE3NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load one image to test\n",
        "image_path = \"learning/train/21/\" + os.listdir(\"learning/train/21\")[0]\n",
        "img = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# Define your test transform list\n",
        "transforms = [\n",
        "    RandomVerticalFlip(),\n",
        "    RandomCropping(0.1),\n",
        "    Rotation(10),\n",
        "    RandomColorJitter(contrast=0.3, hue=0.05, saturation=0.3, brightness=0.3)\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Show the original and augmented images\n",
        "aug_img = apply_transforms(img.copy(), transforms)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Augmented\")\n",
        "plt.imshow(aug_img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FjlMGiLQE1fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#III) Entraînement d'un réseau de neurones"
      ],
      "metadata": {
        "id": "yr2Vzu1xEPpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##III)1) Qu'est-ce qu'il y a dans un réseau de neurone (pour le traitement d'image) ?"
      ],
      "metadata": {
        "id": "YSGuMb6XPEqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load pretrained and randomly initialized ResNet50\n",
        "resnet_pretrained = models.resnet50(pretrained=True)\n",
        "resnet_random = models.resnet50(pretrained=False)\n",
        "\n",
        "# Get first conv layer weights: shape = [64, 3, 7, 7]\n",
        "w_pre = resnet_pretrained.conv1.weight.data.clone()\n",
        "w_rand = resnet_random.conv1.weight.data.clone()\n",
        "\n",
        "show_filters(w_rand, \"Random Init - First Conv Layer (R channel)\")\n",
        "show_filters(w_pre, \"Pretrained on ImageNet - First Conv Layer (R channel)\")\n",
        "del resnet_pretrained, resnet_random"
      ],
      "metadata": {
        "id": "MjPzObSZOcVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/vdumoulin/conv_arithmetic"
      ],
      "metadata": {
        "id": "WpM2Q0SMO7OT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.image-net.org/challenges/LSVRC/2012/index#task"
      ],
      "metadata": {
        "id": "Csh9R6puPO6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III)2) Comment entraîner un tel réseau ?"
      ],
      "metadata": {
        "id": "93MEaLkdPLHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CONFIGURATION  ====\n",
        "config = {\n",
        "    'architecture': 'resnet18',   # 'resnet18' or 'resnet50'\n",
        "    'freeze_backbone': False,\n",
        "    'learning_rate': 0.001,\n",
        "    'batch_size': 32,\n",
        "    'num_epochs': 5,\n",
        "    'image_size': 224,\n",
        "    'train_dir': 'learning/train',\n",
        "    'val_dir': 'learning/val',\n",
        "\n",
        "    'transforms': [\n",
        "        RandomVerticalFlip(),\n",
        "        RandomCropping(0.1),\n",
        "        Rotation(10),\n",
        "        RandomColorJitter(contrast=0.3, hue=0.05, saturation=0.3, brightness=0.3)\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "FQSrUXSuQ6k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compose training transform from config list\n",
        "train_transform = T.Compose(config['transforms'] + [\n",
        "    T.Resize((config['image_size'], config['image_size'])),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "val_transform = T.Compose([\n",
        "    T.Resize((config['image_size'], config['image_size'])),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "train_set = ImageFolder(config['train_dir'], transform=train_transform)\n",
        "val_set = ImageFolder(config['val_dir'], transform=val_transform)\n",
        "class_names = train_set.classes\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=config['batch_size'], shuffle=False)\n",
        "\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Xnt7TRa5VlTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load model architecture\n",
        "if config['architecture'] == 'resnet18':\n",
        "    model = models.resnet18(pretrained=True)\n",
        "elif config['architecture'] == 'resnet50':\n",
        "    model = models.resnet50(pretrained=True)\n",
        "else:\n",
        "    raise ValueError(\"Unsupported architecture.\")\n",
        "\n",
        "# Freeze backbone if needed\n",
        "if config['freeze_backbone']:\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Replace classifier\n",
        "num_classes = len(class_names)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "\n",
        "# Metric tracking\n",
        "train_accs, val_accs = [], []\n",
        "train_bal_accs, val_bal_accs = [], []\n",
        "\n",
        "# === Training Loop ===\n",
        "for epoch in range(config['num_epochs']):\n",
        "    model.train()\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(train_labels, train_preds)\n",
        "    train_bal = balanced_accuracy_score(train_labels, train_preds)\n",
        "    train_accs.append(train_acc)\n",
        "    train_bal_accs.append(train_bal)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_preds, val_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_acc = accuracy_score(val_labels, val_preds)\n",
        "    val_bal = balanced_accuracy_score(val_labels, val_preds)\n",
        "    val_accs.append(val_acc)\n",
        "    val_bal_accs.append(val_bal)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{config['num_epochs']}: \"\n",
        "          f\"Train Acc: {train_acc:.3f}, Val Acc: {val_acc:.3f} | \"\n",
        "          f\"Train BalAcc: {train_bal:.3f}, Val BalAcc: {val_bal:.3f}\")\n"
      ],
      "metadata": {
        "id": "hyfgu7YhRNc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(train_accs, label='Train Accuracy')\n",
        "plt.plot(val_accs, label='Val Accuracy')\n",
        "plt.plot(train_bal_accs, label='Train Balanced Acc', linestyle='--')\n",
        "plt.plot(val_bal_accs, label='Val Balanced Acc', linestyle='--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training & Validation Metrics')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oh2omuD0WR9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IV) Visualisation des prédictions sur le jeu de validation"
      ],
      "metadata": {
        "id": "xD0r6kGdEeBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_confusion_matrix_plotly(model, val_loader, class_names, device)\n"
      ],
      "metadata": {
        "id": "nBM3ocRiV_Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "db2h70FjWoxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_class_prediction_gallery_by_name(model, val_loader, class_names, device, class_name='20')"
      ],
      "metadata": {
        "id": "eIK95P3pYxvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#V) Sauvegarde du réseau et partage vers le compte central"
      ],
      "metadata": {
        "id": "1sEcB2MuEjY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groupe = 14"
      ],
      "metadata": {
        "id": "4MW6PuEwaAxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model weights\n",
        "arch = config['architecture']\n",
        "imgsize = config['image_size']\n",
        "filename = f\"{groupe}_{arch}_{imgsize}.pth\"\n",
        "torch.save(model.state_dict(), filename)\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount drive if not already mounted\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_dir = \"/content/drive/MyDrive/stage_secondes_2025\"\n",
        "os.makedirs(drive_dir, exist_ok=True)\n",
        "\n",
        "# Move file\n",
        "dst_path = os.path.join(drive_dir, filename)\n",
        "shutil.move(filename, dst_path)\n",
        "print(f\"Saved to {dst_path}\")\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Find file ID by name in destination folder\n",
        "file_id = find_file_id(filename, drive_service)\n",
        "\n",
        "# Share with email\n",
        "drive_service.permissions().create(\n",
        "    fileId=file_id,\n",
        "    body={\n",
        "        'type': 'user',\n",
        "        'role': 'reader',\n",
        "        'emailAddress': 'tpdeeplearning@gmail.com'\n",
        "    },\n",
        "    fields='id'\n",
        ").execute()\n",
        "\n",
        "print(f\"Shared {filename} with tpdeeplearning@gmail.com\")"
      ],
      "metadata": {
        "id": "w9rleL9VXS_p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}